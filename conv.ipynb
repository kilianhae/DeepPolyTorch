{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_image = torch.randn(1,5,5)\n",
    "nn = torch.nn.Conv2d(1, 3, 3, padding=0, stride=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_image = nn(in_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "out_channels = nn.out_channels\n",
    "in_channels = nn.in_channels\n",
    "in_height = in_image.size(1)\n",
    "in_width = in_image.size(2)\n",
    "kernel_size = nn.kernel_size[0]\n",
    "out_height = out_image.size(1)\n",
    "out_width = out_image.size(2)\n",
    "weights = nn.weight.detach()\n",
    "stride = nn.stride[0]\n",
    "padding = nn.padding[0]\n",
    "bias = nn.bias\n",
    "print(weights.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3, 3])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_image.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100000, 3, 66, 66])\n",
      "torch.Size([100000, 6, 32, 32])\n",
      "torch.Size([3, 3, 3])\n",
      "torch.Size([100000])\n",
      "torch.Size([100000])\n",
      "torch.Size([100000])\n",
      "torch.Size([100000])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/kilianhaefeli/ETH/RTAI23_project/conv.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kilianhaefeli/ETH/RTAI23_project/conv.ipynb#W4sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m             el \u001b[39m=\u001b[39m ub_mult[:,i_out,i_h,i_w]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kilianhaefeli/ETH/RTAI23_project/conv.ipynb#W4sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m             \u001b[39mprint\u001b[39m(el\u001b[39m.\u001b[39msize())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/kilianhaefeli/ETH/RTAI23_project/conv.ipynb#W4sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             im[:,:,stride\u001b[39m*\u001b[39mi_h:stride\u001b[39m*\u001b[39mi_h\u001b[39m+\u001b[39mkernel_size, stride\u001b[39m*\u001b[39mi_w:stride\u001b[39m*\u001b[39mi_w\u001b[39m+\u001b[39mkernel_size] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m el\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m channel_weights\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kilianhaefeli/ETH/RTAI23_project/conv.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mif\u001b[39;00m padding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/kilianhaefeli/ETH/RTAI23_project/conv.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     im \u001b[39m=\u001b[39m im[:,padding:\u001b[39m-\u001b[39mpadding,padding:\u001b[39m-\u001b[39mpadding]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "now=time.time()\n",
    "\n",
    "padded_size = list(in_image.size())\n",
    "padded_size = [ub_mult.size(0)] + padded_size\n",
    "padded_size[2] = padded_size[2] + 2 * padding\n",
    "padded_size[3] = padded_size[3] + 2 * padding\n",
    "\n",
    "ub_mult = torch.reshape(ub_mult, (ub_mult.size(0),out_channels, out_height, out_width))\n",
    "im = torch.zeros(padded_size)\n",
    "print(im.size())\n",
    "print(ub_mult.size())\n",
    "\n",
    "for i_out in range(out_channels):\n",
    "    channel_weights = weights[i_out]\n",
    "    print(channel_weights.size())\n",
    "    for i_h in range(out_height):\n",
    "        for i_w in range(out_width):\n",
    "            el = ub_mult[:,i_out,i_h,i_w]\n",
    "            print(el.size())\n",
    "            im[:,:,stride*i_h:stride*i_h+kernel_size, stride*i_w:stride*i_w+kernel_size] += el.view(-1,1,1,1) * channel_weights\n",
    "            \n",
    "if padding > 0:\n",
    "    im = im[:,padding:-padding,padding:-padding]\n",
    "print(time.time()-now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n",
      "torch.Size([1, 6])\n",
      "tensor([48.1798, 48.1798, 48.1798, 48.1798, 48.1798, 48.1798, 48.1798, 48.1798,\n",
      "        48.1798, 48.1798], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "ub_mult.shape\n",
    "\n",
    "sum=ub_mult.sum(dim=[2,3])\n",
    "bias_r = bias.view(1,-1)\n",
    "(sum * bias_r).sum(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0013,  0.1298, -0.1485,  ..., -0.2031,  0.1664, -0.0834],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000, -0.2651, -0.1284, -0.2169,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000, -0.2651, -0.1284, -0.2169,\n",
      "          0.0000,  0.0000, -0.3018,  0.0530, -0.0255],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000, -0.2651, -0.1284, -0.2169,\n",
      "          0.0000,  0.0000, -0.3018,  0.0530, -0.0255],\n",
      "        [ 0.0814,  0.0953, -0.2766,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000, -0.2651, -0.1284, -0.2169,\n",
      "          0.0000,  0.0000, -0.3018,  0.0530, -0.0255],\n",
      "        [ 0.0814,  0.0953, -0.2766,  0.0000,  0.0000,  0.1166, -0.3143,  0.1683,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000, -0.2651, -0.1284, -0.2169,\n",
      "          0.0000,  0.0000, -0.3018,  0.0530, -0.0255],\n",
      "        [ 0.0814,  0.0953, -0.2766,  0.0000,  0.0000,  0.1166, -0.3143,  0.1683,\n",
      "          0.0000,  0.0000, -0.2526,  0.1169, -0.0217],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000, -0.2651, -0.1284, -0.2169,\n",
      "          0.0000,  0.0000, -0.3018,  0.0530, -0.0255],\n",
      "        [ 0.0814,  0.0953, -0.2766,  0.0000,  0.0000,  0.1166, -0.3143,  0.1683,\n",
      "          0.0000,  0.0000, -0.2526,  0.1169, -0.0217],\n",
      "        [-0.2883, -0.2479, -0.2666,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000, -0.2651, -0.1284, -0.2169,\n",
      "          0.0000,  0.0000, -0.3018,  0.0530, -0.0255],\n",
      "        [ 0.0814,  0.0953, -0.2766,  0.0000,  0.0000,  0.1166, -0.3143,  0.1683,\n",
      "          0.0000,  0.0000, -0.2526,  0.1169, -0.0217],\n",
      "        [-0.2883, -0.2479, -0.2666,  0.0000,  0.0000, -0.3239,  0.1171,  0.2155,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n",
      "tensor([[-0.0385, -0.0475, -0.0795,  0.0000,  0.0000, -0.2651, -0.1284, -0.2169,\n",
      "          0.0000,  0.0000, -0.3018,  0.0530, -0.0255],\n",
      "        [ 0.0814,  0.0953, -0.2766,  0.0000,  0.0000,  0.1166, -0.3143,  0.1683,\n",
      "          0.0000,  0.0000, -0.2526,  0.1169, -0.0217],\n",
      "        [-0.2883, -0.2479, -0.2666,  0.0000,  0.0000, -0.3239,  0.1171,  0.2155,\n",
      "          0.0000,  0.0000,  0.2793,  0.0767,  0.2851]])\n",
      "0.014225006103515625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "now=time.time()\n",
    "in_width_p = in_width + padding * 2\n",
    "in_height_p = in_height + padding * 2\n",
    "\n",
    "size_p = in_height_p * in_width_p\n",
    "in_dim = size_p * in_channels\n",
    "out_dim = out_height * out_width * out_channels\n",
    "res = torch.zeros((out_dim, in_dim))\n",
    "\n",
    "# build row fillers\n",
    "len_rows = (in_channels - 1) * size_p + (kernel_size - 1) * in_width_p + kernel_size\n",
    "channels = torch.zeros((out_channels, len_rows))\n",
    "\n",
    "for i_out in range(out_channels):\n",
    "    for i_in in range(in_channels):\n",
    "        i_p = i_in * size_p\n",
    "        for k in range(kernel_size):\n",
    "            start = i_p + k * in_width_p\n",
    "            end = start + kernel_size\n",
    "            channels[i_out, start:end] = weights[i_out, i_in, k]\n",
    "            print(channels)\n",
    "\n",
    "    for i_out_height in range(out_height):\n",
    "        for i_out_width in range(out_width):\n",
    "            start = i_out_height * stride * in_width_p + i_out_width * stride\n",
    "            end = start + len_rows\n",
    "            output = i_out * out_height * out_width + i_out_height * out_width + i_out_width\n",
    "            res[output, start:end] = channels[i_out]\n",
    "\n",
    "# remove padding\n",
    "padding_rows = []\n",
    "for i_in in range(in_channels):\n",
    "    for i_in_height in range(in_height_p):\n",
    "        for i_in_width in range(in_width_p):\n",
    "            if i_in_width < padding or i_in_width >= padding + in_width:\n",
    "                padding_rows.append(i_in * size_p + i_in_height * in_width_p + i_in_width)\n",
    "\n",
    "        if i_in_height < padding or i_in_height >= padding + in_height:\n",
    "            start = i_in * size_p + i_in_height * in_width_p\n",
    "            end = start + in_width_p\n",
    "            padding_rows = padding_rows + list(range(start, end))\n",
    "\n",
    "padding_rows = list(np.unique(np.array(padding_rows)))  # delete duplicates\n",
    "\n",
    "lc = torch.from_numpy(np.delete(res.numpy(), padding_rows, axis=1)).detach()\n",
    "\n",
    "if bias is None:\n",
    "    ret_bias = torch.zeros(out_width * out_height * out_channels)\n",
    "else:\n",
    "    ret_bias = torch.repeat_interleave(bias, out_width * out_height)\n",
    "print(time.time()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0385,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0814,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.2883,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [-0.0475, -0.0385,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0953,  0.0814,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.2479, -0.2883,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [-0.0795, -0.0475, -0.0385,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.2766,  0.0953,  0.0814,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.2666, -0.2479, -0.2883,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.0795, -0.0475,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.2766,  0.0953,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.2666, -0.2479,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, -0.0795,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000, -0.2766,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, -0.2666,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [-0.2651,  0.0000,  0.0000, -0.0385,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.1166,  0.0000,  0.0000,  0.0814,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000, -0.3239,  0.0000,  0.0000, -0.2883,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [-0.1284, -0.2651,  0.0000, -0.0475, -0.0385,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.3143,  0.1166,  0.0000,  0.0953,  0.0814,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.1171, -0.3239,  0.0000, -0.2479, -0.2883,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [-0.2169, -0.1284, -0.2651, -0.0795, -0.0475, -0.0385,  0.0000,  0.0000,\n",
       "          0.0000,  0.1683, -0.3143,  0.1166, -0.2766,  0.0953,  0.0814,  0.0000,\n",
       "          0.0000,  0.0000,  0.2155,  0.1171, -0.3239, -0.2666, -0.2479, -0.2883,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000, -0.2169, -0.1284,  0.0000, -0.0795, -0.0475,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.1683, -0.3143,  0.0000, -0.2766,  0.0953,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.2155,  0.1171,  0.0000, -0.2666, -0.2479,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000, -0.2169,  0.0000,  0.0000, -0.0795,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.1683,  0.0000,  0.0000, -0.2766,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.2155,  0.0000,  0.0000, -0.2666,\n",
       "          0.0000,  0.0000,  0.0000],\n",
       "        [-0.3018,  0.0000,  0.0000, -0.2651,  0.0000,  0.0000, -0.0385,  0.0000,\n",
       "          0.0000, -0.2526,  0.0000,  0.0000,  0.1166,  0.0000,  0.0000,  0.0814,\n",
       "          0.0000,  0.0000,  0.2793,  0.0000,  0.0000, -0.3239,  0.0000,  0.0000,\n",
       "         -0.2883,  0.0000,  0.0000],\n",
       "        [ 0.0530, -0.3018,  0.0000, -0.1284, -0.2651,  0.0000, -0.0475, -0.0385,\n",
       "          0.0000,  0.1169, -0.2526,  0.0000, -0.3143,  0.1166,  0.0000,  0.0953,\n",
       "          0.0814,  0.0000,  0.0767,  0.2793,  0.0000,  0.1171, -0.3239,  0.0000,\n",
       "         -0.2479, -0.2883,  0.0000],\n",
       "        [-0.0255,  0.0530, -0.3018, -0.2169, -0.1284, -0.2651, -0.0795, -0.0475,\n",
       "         -0.0385, -0.0217,  0.1169, -0.2526,  0.1683, -0.3143,  0.1166, -0.2766,\n",
       "          0.0953,  0.0814,  0.2851,  0.0767,  0.2793,  0.2155,  0.1171, -0.3239,\n",
       "         -0.2666, -0.2479, -0.2883],\n",
       "        [ 0.0000, -0.0255,  0.0530,  0.0000, -0.2169, -0.1284,  0.0000, -0.0795,\n",
       "         -0.0475,  0.0000, -0.0217,  0.1169,  0.0000,  0.1683, -0.3143,  0.0000,\n",
       "         -0.2766,  0.0953,  0.0000,  0.2851,  0.0767,  0.0000,  0.2155,  0.1171,\n",
       "          0.0000, -0.2666, -0.2479],\n",
       "        [ 0.0000,  0.0000, -0.0255,  0.0000,  0.0000, -0.2169,  0.0000,  0.0000,\n",
       "         -0.0795,  0.0000,  0.0000, -0.0217,  0.0000,  0.0000,  0.1683,  0.0000,\n",
       "          0.0000, -0.2766,  0.0000,  0.0000,  0.2851,  0.0000,  0.0000,  0.2155,\n",
       "          0.0000,  0.0000, -0.2666],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.3018,  0.0000,  0.0000, -0.2651,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000, -0.2526,  0.0000,  0.0000,  0.1166,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2793,  0.0000,  0.0000,\n",
       "         -0.3239,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0530, -0.3018,  0.0000, -0.1284, -0.2651,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.1169, -0.2526,  0.0000, -0.3143,\n",
       "          0.1166,  0.0000,  0.0000,  0.0000,  0.0000,  0.0767,  0.2793,  0.0000,\n",
       "          0.1171, -0.3239,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000, -0.0255,  0.0530, -0.3018, -0.2169, -0.1284,\n",
       "         -0.2651,  0.0000,  0.0000,  0.0000, -0.0217,  0.1169, -0.2526,  0.1683,\n",
       "         -0.3143,  0.1166,  0.0000,  0.0000,  0.0000,  0.2851,  0.0767,  0.2793,\n",
       "          0.2155,  0.1171, -0.3239],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000, -0.0255,  0.0530,  0.0000, -0.2169,\n",
       "         -0.1284,  0.0000,  0.0000,  0.0000,  0.0000, -0.0217,  0.1169,  0.0000,\n",
       "          0.1683, -0.3143,  0.0000,  0.0000,  0.0000,  0.0000,  0.2851,  0.0767,\n",
       "          0.0000,  0.2155,  0.1171],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0255,  0.0000,  0.0000,\n",
       "         -0.2169,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0217,  0.0000,\n",
       "          0.0000,  0.1683,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.2851,\n",
       "          0.0000,  0.0000,  0.2155],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.3018,  0.0000,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.2526,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.2793,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0530, -0.3018,\n",
       "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.1169,\n",
       "         -0.2526,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0767,  0.2793,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0255,  0.0530,\n",
       "         -0.3018,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0217,\n",
       "          0.1169, -0.2526,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.2851,  0.0767,  0.2793],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -0.0255,\n",
       "          0.0530,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0217,  0.1169,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.2851,  0.0767],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "         -0.0255,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000, -0.0217,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000,  0.2851]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lc.transpose(0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0385, -0.0475, -0.0795],\n",
       "          [-0.2651, -0.1284, -0.2169],\n",
       "          [-0.3018,  0.0530, -0.0255]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0814,  0.0953, -0.2766],\n",
       "          [ 0.1166, -0.3143,  0.1683],\n",
       "          [-0.2526,  0.1169, -0.0217]]],\n",
       "\n",
       "\n",
       "        [[[-0.2883, -0.2479, -0.2666],\n",
       "          [-0.3239,  0.1171,  0.2155],\n",
       "          [ 0.2793,  0.0767,  0.2851]]]], requires_grad=True)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "inconsistent tensor size, expected tensor [614400] and src [6144] to have the same number of elements, but got 614400 and 6144 elements respectively",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/kilianhaefeli/ETH/RTAI23_project/conv.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/kilianhaefeli/ETH/RTAI23_project/conv.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m out_image\u001b[39m.\u001b[39mflatten() \u001b[39m@\u001b[39m ret_bias\n",
      "\u001b[0;31mRuntimeError\u001b[0m: inconsistent tensor size, expected tensor [614400] and src [6144] to have the same number of elements, but got 614400 and 6144 elements respectively"
     ]
    }
   ],
   "source": [
    "class DP_Conv2D(nn.Module):\n",
    "    def _init_(self, inner: nn.Conv2d, input_shape):\n",
    "        super()._init_()\n",
    "\n",
    "        self.in_channels = inner.in_channels\n",
    "        self.out_channels = inner.out_channels\n",
    "\n",
    "        self.kernel_size = inner.kernel_size[0]\n",
    "        self.stride = inner.stride[0]\n",
    "        self.padding = inner.padding[0]\n",
    "        \n",
    "        self.in_width = int(sqrt(input_shape / self.in_channels)) # did not work for colour channels \n",
    "        self.out_height= int((self.in_width + 2 * self.padding - self.kernel_size) / self.stride + 1)\n",
    "        self.out_features = (self.out_height**2) * self.out_channels\n",
    "\n",
    "        self.weight = inner.weight.detach().clone()\n",
    "        self.matrix = self.build_matrix()\n",
    "\n",
    "        if inner.bias != None:\n",
    "            self.bias = inner.bias.detach().clone()\n",
    "            self.bias_matrix = torch.repeat_interleave(self.bias, int(self.out_features/self.out_channels))\n",
    "            \n",
    "        else:\n",
    "            self.bias_matrix = torch.zeros(self.out_features)\n",
    "\n",
    "        # print(self.matrix.shape)\n",
    "        # assert self.matrix.shape[1] == self.bias_matrix.shape[0], 'fuckup with dims in conv matrix layers'\n",
    "\n",
    "    def build_matrix(self):\n",
    "        concat_weights = np.zeros((1,self.in_width**2 * self.in_channels))  \n",
    "\n",
    "        for i in range(self.out_channels):\n",
    "            # loop over output channels and then append to the lower side\n",
    "\n",
    "            weights_per_in_channel = []\n",
    "            for j in range(self.in_channels):\n",
    "                # loop over input channels and then append to the right side\n",
    "                # print(i,j)\n",
    "                    \n",
    "                kernel_mat = self.weight[i,j,:,:]\n",
    "                idx = np.arange((self.in_width+ 2*self.padding)**2)\n",
    "\n",
    "                # cut away first rows of padding\n",
    "                cond1 = idx < (self.in_width + 2*self.padding) * self.padding\n",
    "\n",
    "                # cut away lower row of padding\n",
    "                cond2 = idx >= (self.in_width + 2*self.padding) * (self.in_width + self.padding)\n",
    "\n",
    "                # cut away left columns of padding\n",
    "                cond3 = idx % (self.in_width + 2*self.padding) < self.padding\n",
    "\n",
    "                # cut away right columns of padding\n",
    "                cond4 = idx % (self.in_width + 2*self.padding) >= (self.in_width+ self.padding)\n",
    "\n",
    "                remove_padding = np.logical_or.reduce(\n",
    "                    (cond1, cond2, cond3, cond4)\n",
    "                )\n",
    "\n",
    "                # right columns not considered by kernel\n",
    "                cond5 = idx % (self.in_width + 2*self.padding) > ((self.in_width+ 2*self.padding) - self.kernel_size)\n",
    "\n",
    "                # lower rows not considered by kernel\n",
    "                cond6 = idx >= (self.in_width + 2*self.padding) * (self.in_width + 2*self.padding - self.kernel_size + 1)\n",
    "\n",
    "                if self.stride > 0:\n",
    "                    cond7 = idx % (self.in_width + 2*self.padding) % self.stride != 0\n",
    "                    cond8 = idx // (self.in_width + 2*self.padding)  % self.stride != 0\n",
    "                else:\n",
    "                    cond7 = np.zeros_like(cond1).astype(bool)\n",
    "                    cond8 = np.zeros_like(cond1).astype(bool)\n",
    "\n",
    "                remove_rows = np.logical_or.reduce(\n",
    "                    (cond5, cond6, cond7, cond8)\n",
    "                )\n",
    "                \n",
    "                row_toep = np.vstack(\n",
    "                    (\n",
    "                        np.hstack(\n",
    "                            (\n",
    "                                kernel_mat, \n",
    "                                np.zeros(\n",
    "                                    (\n",
    "                                        self.kernel_size, \n",
    "                                        self.in_width + 2*self.padding - self.kernel_size\n",
    "                                    )\n",
    "                                )\n",
    "                            )\n",
    "                        ),\n",
    "                        np.zeros(\n",
    "                            (\n",
    "                                self.in_width + 2*self.padding - self.kernel_size, \n",
    "                                self.in_width + 2*self.padding\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                ).reshape(-1)\n",
    "\n",
    "                toep_mat = row_toeplitz(row_toep)\n",
    "                weights = toep_mat[~remove_rows, :][:, ~remove_padding]\n",
    "                weights_per_in_channel.append(weights)\n",
    "\n",
    "            if self.in_channels > 1:\n",
    "                # first concatenate all the weights -> direction before we append it to np array\n",
    "                concat_weights = np.vstack((\n",
    "                    concat_weights, \n",
    "                    np.concatenate(tuple(weights_per_in_channel), axis=1)\n",
    "                ))\n",
    "            else:\n",
    "                # we have to write the loop otherwise concatenate will fail\n",
    "                concat_weights = np.vstack((concat_weights, weights))\n",
    "\n",
    "        return torch.tensor(concat_weights[1:,:], dtype = torch.float32)\n",
    "      \n",
    "    def forward(self, x: DeepPoly):\n",
    "\n",
    "        lb_weights, ub_weights = self.matrix, self.matrix\n",
    "        lb_bias, ub_bias = self.bias_matrix, self.bias_matrix\n",
    "\n",
    "        new_lb_weights, new_lb_bias, new_ub_weights, new_ub_bias = backsub(\n",
    "            lb_weights,\n",
    "            lb_bias,\n",
    "            ub_weights,\n",
    "            ub_bias,\n",
    "            parent = x\n",
    "        )\n",
    "\n",
    "        return DeepPoly(new_lb_weights, new_lb_bias, new_ub_weights, new_ub_bias, parent=x)\n",
    "#        return DeepPoly(lb_weights, lb_bias, ub_weights, ub_bias, parent=x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reliable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
